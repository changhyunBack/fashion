# backend/main.py  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  (Streaming, ì¦‰ì‹œ í”ŒëŸ¬ì‹œ)
# streamingì²˜ë¦¬ê¹Œì§€ ì™„ë£Œëœ ë²„ì „ (front app2ì™€ í˜¸í™˜)
import os, uuid, datetime as dt, hmac, hashlib, base64, time
from typing import List, Optional

from fastapi import FastAPI, HTTPException, Depends, Header
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from sqlalchemy import create_engine, Column, String, DateTime, ForeignKey, select, delete
from sqlalchemy.orm import Session, declarative_base, sessionmaker, relationship
from dotenv import load_dotenv, find_dotenv
import asyncio, aiosqlite
import nest_asyncio
from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver

# â”€â”€ LangChain / LangGraph â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from openai import OpenAI
from langchain_openai import ChatOpenAI
from langchain.agents import tool
from langgraph.prebuilt import create_react_agent
from langchain_core.messages import HumanMessage
from langchain_core.runnables import RunnableConfig
from langchain_tavily import TavilySearch
from langchain_experimental.tools.python.tool import PythonREPLTool
from graphparser.rag_tool import make_rag_tool
import operator
from typing import Sequence, Annotated
from typing_extensions import TypedDict
from langchain_core.messages import BaseMessage

# â”€â”€ ê¸°ë³¸ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv(find_dotenv())
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
SECRET         = os.getenv("APP_SECRET", "change-me")

if not OPENAI_API_KEY:
    raise RuntimeError(
        "OPENAI_API_KEY environment variable is missing. \n"
        "Set it in a `.env` file or export it before running the server."
    )

VECTOR_STORE1_ID = "vs_6822d7e1761881918b5ee78d3d689562"
VECTOR_STORE2_ID = "vs_6822d7e5e79881919418a3bea0987f89"

#####################################################################
# â”€â”€ LangGraph ì—ì´ì „íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#####################################################################
client = OpenAI(api_key=OPENAI_API_KEY)
llm    = ChatOpenAI(model="gpt-4.1-mini", temperature=0)
vision_llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# ìƒíƒœ ì •ì˜
class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], operator.add]  # ë©”ì‹œì§€
    next: str  # ë‹¤ìŒìœ¼ë¡œ ë¼ìš°íŒ…í•  ì—ì´ì „íŠ¸

# ìµœëŒ€ 5ê°œì˜ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” Tavily ê²€ìƒ‰ ë„êµ¬ 
tavily_tool=TavilySearch(max_results=5,topic="general",include_raw_content=True)
# ë¡œì»¬ì—ì„œ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ëŠ” Python REPL ë„êµ¬ 
python_repl_tool = PythonREPLTool()
# DBì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” ë„êµ¬ (RAG_processë¥¼ ì—¬ê¸°ë‹¤ê°€ íƒ‘ì¬)
rag_search_tool = make_rag_tool("RS")

@tool
def analyze_image(url: str, prompt: str) -> str:
    """Analyze the given image (URL or base64) with the prompt."""
    msg = HumanMessage(content=[
        {"type": "text", "text": prompt},
        {"type": "image_url", "image_url": {"url": url}},
    ])
    return vision_llm.invoke([msg]).content

async def _init_saver(db_path: str = "lg.sqlite"):
    conn = await aiosqlite.connect(db_path)
    return AsyncSqliteSaver(conn)

try:
    # If we're in a fresh context with no running loop
    checkpointer = asyncio.run(_init_saver())
except RuntimeError:
    # Already inside an event loop (e.g., uvicorn --reload)
    nest_asyncio.apply()
    loop = asyncio.get_event_loop()
    checkpointer = loop.run_until_complete(_init_saver())

# Research Agent ìƒì„±
research_prompt="""
You are a **â€œresearch_agentâ€**.  
Your sole responsibility is to collect and organize information relevant to the userâ€™s query using **only reliable, verifiable sources**.  
If you do not know the answer, state this explicitly.  
**All responses must be written in Korean.**

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
## Unified Guidelines  (DO NOT OMIT)

1. **Understand the Intent**  
   â€¢ Precisely grasp the context and scope of the question and why the user is asking it.

2. **Gather Trustworthy Information**  
   â€¢ Identify key terms.  
   â€¢ **Retrieval order:** always attempt **`rag_search_tool`** first; use **`web_search_tool`** only if the RAG search yields insufficient material.  
   â€¢ Search academic papers, government or official institutional websites, reputable databases, and major news outlets only.  
   â€¢ Prioritize recent, fact-checked data and cross-verify all facts.

3. **Present Information**  
   â€¢ **Use *only* the text contained in the retrieved `<document>` elements.**  
   â€¢ Provide content **verbatim from the source**â€”do **not** paraphrase, summarize, interpret, or add outside knowledge.  
   â€¢ Organize core information into coherent paragraphs; add concise tables only when they add clear value.  
   â€¢ If the answer is uncertain, clearly state **â€œëª¨ë¥¸ë‹¤â€** (â€œI donâ€™t knowâ€) or **â€œìë£Œ ë¶€ì¡±â€** (â€œInsufficient dataâ€).  
   â€¢ Minimize hallucinations: generating any statement not present in the retrieved documents is strictly forbidden.

4. **Source Formatting**  
   â€¢ Begin every answer with:  
     `ì´ ë‹µë³€ì€ ë¬¸ì„œ **ğŸ“šì—ì„œ ë°œê²¬ëœ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤`  
   â€¢ End with:  
     `**ğŸ“Œ ì¶œì²˜**`  
     and list *all* sources in the form `- filename.pdf, page` (page numbers must be integers).  
   â€¢ **STRICT RULES FOR CITATIONS**  
     1) Use the **exact filename** from each `<source>` tagâ€”never rename, translate, or invent filenames.  
     2) Use the **exact page number** (integer) from each `<page>` tag.  
     3) Cite **only** files and pages that actually occur in the retrieved context; inventing or extrapolating pages is forbidden.  
     4) If multiple `<document>` elements reference the same file and contiguous pages, you may combine them as a range (e.g., `8~9ìª½`); otherwise list each page separately.  
     5) If a source appears multiple times, list it **once**.

5. **Language & Tone**  
   â€¢ Respond **entirely in Korean**.  
   â€¢ Avoid speculation or definitive claims without evidence; acknowledge uncertainty plainly.  
   â€¢ Be concise yet sufficiently detailed, eliminating unnecessary verbosity.

6. **Mandatory Elements**  
   1) Include all sources and page numbers exactly as described above.  
   2) Include tables only when relevant to the context.  
   3) Include image explanations if images appear in the source.  
   4) Provide the fullest detail possible within factual bounds.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
## Directions (workflow checklist)

1. **Clarify** the questionâ€™s intent and scope.  
2. **Select** the most relevant content directly tied to the query.  
3. **Compose** a concise, logical answer using **only** the retrieved text, arranging citations so the text flows naturally.  
4. If no relevant material is found, reply: *â€˜ë‚´ê°€ ê°€ì§€ê³  ìˆëŠ” ìë£Œì—ì„œ ê·¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤â€™*.  
5. Present any key points in a table when useful.  
6. Attach every citation with page numbers (see Source Formatting rules).  
7. Always answer in Korean.  
8. Provide maximum feasible detail.  
9. Start with the required header and finish with **ğŸ“Œ ì¶œì²˜**.  
10. Page numbers must be integers.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
## Example Answer  (template)

(brief summary of the answer)  
(include table if there is a table in the context related to the question)  
(include image explanation if there is an image in the context related to the question)  
(detailed answer to the question)

**ğŸ“Œ ì¶œì²˜**  
[here you only write filename(.pdf only), page]  
- íŒŒì¼ëª….pdf, 192ìª½  
- íŒŒì¼ëª….pdf, 193ìª½  
- ...
"""
research_agent = create_react_agent(llm, tools=[rag_search_tool],prompt=research_prompt, name='research_agent')

# Coder Agent 
code_system_prompt = """
Be sure to use the following font in your code for visualization.
----------------------------------------------------------------
##### í°íŠ¸ ì„¤ì • #####
import platform

# OS íŒë‹¨
current_os = platform.system()

if current_os == "Windows":
    # Windows í™˜ê²½ í°íŠ¸ ì„¤ì •
    font_path = "C:/Windows/Fonts/malgun.ttf"  # ë§‘ì€ ê³ ë”• í°íŠ¸ ê²½ë¡œ
    fontprop = fm.FontProperties(fname=font_path, size=12)
    plt.rc("font", family=fontprop.get_name())
elif current_os == "Darwin":  # macOS
    # Mac í™˜ê²½ í°íŠ¸ ì„¤ì •
    plt.rcParams["font.family"] = "AppleGothic"
else:  # Linux ë“± ê¸°íƒ€ OS
    # ê¸°ë³¸ í•œê¸€ í°íŠ¸ ì„¤ì • ì‹œë„
    try:
        plt.rcParams["font.family"] = "NanumGothic"
    except:
        print("í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

##### ë§ˆì´ë„ˆìŠ¤ í°íŠ¸ ê¹¨ì§ ë°©ì§€ #####
plt.rcParams["axes.unicode_minus"] = False  # ë§ˆì´ë„ˆìŠ¤ í°íŠ¸ ê¹¨ì§ ë°©ì§€
"""

# Coder Agent ìƒì„±
coder_agent = create_react_agent(
    model=llm,
    tools=[python_repl_tool],
    prompt=code_system_prompt, 
    name = "coder_agent"
)


# Websearch Agent ìƒì„±
webserach_system_prompt="""
### SYSTEM PROMPT â€” â€œsearch_agentâ€ (General-purpose Web Information Retrieval)

You are **â€œsearch_agent.â€**  
Your role is to answer user questions that are *not* related to quality-engineering or reliability domain knowledge by using the web search tool **`tavily_search`.**  
Respond **in Korean** and always include explicit source links (URLs).

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
## 1. Behaviour Guidelines

1. **Execute a Search**  
   â€¢ Rewrite the userâ€™s question into a concise query sentence.  
   â€¢ Call **`tavily_search`** with these options:  
     `max_results=5`, `include_raw_content=True`.

2. **Filter & Validate**  
   â€¢ From the top results, keep those from trustworthy domains (government sites, respected news outlets, academic sources).  
   â€¢ Remove duplicate articles from the same domain.

3. **Compose the Answer**  
   â€¢ Summarise key facts in coherent paragraphs or numbered lists.  
   â€¢ Do not add any information that is absent from the retrieved results.  
   â€¢ If essential data is missing, explicitly state **â€œëª¨ë¥¸ë‹¤â€** or **â€œìë£Œ ë¶€ì¡±.â€**  
   â€¢ Quote numbers or statements exactly as they appear in the source.

4. **Cite Sources**  
   â€¢ Finish every answer with the header **â€œğŸ“Œ ì¶œì²˜.â€**  
   â€¢ List each citation as a Markdown link:  
     `- [Title](URL)`

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
## 2. Output Format (Example)

(Concise explanation of the answer)

**ğŸ“Œ ì¶œì²˜**  
- [OECD Health Statistics â€“ Life Expectancy](https://stats.oecd.org/Index.aspx?DataSetCode=HEALTH_STAT)  
- [WHO Fact Sheet: Air Pollution](https://www.who.int/news-room/fact-sheets/detail/ambient-(outdoor)-air-quality-and-health)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
## 3. Failure Handling

If no relevant information is found or critical details are missing, reply:  
**â€œë‚´ê°€ ê°€ì§€ê³  ìˆëŠ” ê²€ìƒ‰ ê²°ê³¼ë¡œëŠ” ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤.â€**
"""

websearcher_agent = create_react_agent(model= llm, tools=[tavily_tool], prompt=webserach_system_prompt, name='websearcher_agent')

from langgraph_supervisor import create_supervisor
app = create_supervisor(
    [research_agent, websearcher_agent, coder_agent],
    model=llm,
    prompt=(
        "You are the team supervisor. Your job is to orchestrate multiple specialist agents to achieve the user's goal.\n"
        "\n"
        "There are three subordinate agents you can delegate tasks to:\n"
        "â€¢ research_agent â€” use this when you need information in the reliability or qualityâ€‘engineering domain.\n"
        "â€¢ websearcher_agent â€” use this when you need upâ€‘toâ€‘date information such as breaking news or other recent web content.\n"
        "â€¢ coder_agent â€” use this when you need to write or execute code, do calculations, or create visualizations.\n"
        "\n"
        "Workflow rules:\n"
        "1. Decide which agent(s) to call and in what order.\n"
        "2. After an agent returns, carefully read its answer. **If the answer contains a citation or 'ğŸ“Œ ì¶œì²˜' block, you must preserve it verbatim in your final reply.**\n"
        "3. If an agent omits citations when they are required (e.g. research_agent answer without 'ğŸ“Œ ì¶œì²˜'), ask that agent once more for the sources, then include them.\n"
        "4. When you have enough information, reply to the user in Korean, keeping any citation block exactly as given (do not paraphrase or remove it).\n"
        "\n"
        "Always follow these rules. Never invent citations."
    ),
)
agent= app.compile(checkpointer=checkpointer)

# â”€â”€ SQLite ORM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Base   = declarative_base()
engine = create_engine("sqlite:///chat.db", connect_args={"check_same_thread": False})
SessionLocal = sessionmaker(bind=engine, expire_on_commit=False)

class Thread(Base):
    __tablename__ = "threads"
    id       = Column(String, primary_key=True)
    user_id  = Column(String, index=True)
    title    = Column(String, default="ìƒˆ ëŒ€í™”")
    created  = Column(DateTime, default=dt.datetime.utcnow)
    messages = relationship("Message", cascade="all,delete")

class Message(Base):
    __tablename__ = "messages"
    id        = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    thread_id = Column(String, ForeignKey("threads.id"))
    role      = Column(String)   # "user" | "assistant"
    content   = Column(String)
    ts        = Column(DateTime, default=dt.datetime.utcnow)
    images    = relationship("MessageImage", cascade="all,delete", back_populates="message")


class MessageImage(Base):
    __tablename__ = "message_images"
    id         = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    message_id = Column(String, ForeignKey("messages.id"))
    data       = Column(String)  # base64 encoded image
    message    = relationship("Message", back_populates="images")

Base.metadata.create_all(engine)

def get_db():
    db = SessionLocal()
    try:    yield db
    finally: db.close()

# â”€â”€ ê°„ë‹¨ í† í° util ------------------------------------------------------------
def sign(user: str) -> str:
    sig = hmac.new(SECRET.encode(), user.encode(), hashlib.sha256).digest()
    return f"{user}.{base64.urlsafe_b64encode(sig).decode()}"

def verify(tok: str) -> str:
    try:
        user, sig = tok.split(".")
        expect = base64.urlsafe_b64encode(
            hmac.new(SECRET.encode(), user.encode(), hashlib.sha256).digest()
        ).decode()
        if hmac.compare_digest(sig, expect):
            return user
    except Exception:
        ...
    raise HTTPException(401, "Invalid token")

def current_user(auth: str = Header(..., alias="Authorization")):
    if not auth.startswith("Bearer "):
        raise HTTPException(401, "Bearer required")
    return verify(auth.removeprefix("Bearer ").strip())

# â”€â”€ FastAPI ì•± ì „ì—­ -----------------------------------------------------------
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# 1) ë¡œê·¸ì¸ --------------------------------------------------------------------
class LoginReq(BaseModel):
    user: str
    key: str

@app.post("/login")
def login(body: LoginReq):
    if body.key != "open-sesame" or len(body.user) < 3:
        raise HTTPException(401, "Bad credentials")
    return {"token": sign(body.user)}

# 2) Thread CRUD --------------------------------------------------------------
@app.post("/threads")
def new_thread(db: Session = Depends(get_db), user=Depends(current_user)):
    tid = str(uuid.uuid4())
    db.add(Thread(id=tid, user_id=user)); db.commit()
    return {"thread_id": tid, "title": "ìƒˆ ëŒ€í™”"}

@app.get("/threads", response_model=List[dict])
def list_threads(db: Session = Depends(get_db), user=Depends(current_user)):
    rows = db.scalars(select(Thread).where(Thread.user_id == user)).all()
    return [{"id": t.id, "title": t.title} for t in rows]

@app.patch("/threads/{tid}")
def rename_thread(tid: str, body: dict,
                  db: Session = Depends(get_db),
                  user=Depends(current_user)):
    new_title = body.get("title", "").strip()[:50] or "ì œëª© ì—†ìŒ"
    th = db.get(Thread, tid)
    if not th or th.user_id != user: raise HTTPException(404)
    th.title = new_title; db.commit()
    return {"ok": True, "title": new_title}

@app.delete("/threads/{tid}")
def delete_thread(tid: str, db: Session = Depends(get_db), user=Depends(current_user)):
    rows = db.execute(delete(Thread).where(Thread.id == tid,
                                           Thread.user_id == user)).rowcount
    if rows: db.commit(); return {"ok": True}
    raise HTTPException(404)

# 3) ë©”ì‹œì§€ ì¡°íšŒ ---------------------------------------------------------------
@app.get("/messages/{tid}", response_model=List[dict])
def get_messages(tid: str, db: Session = Depends(get_db), user=Depends(current_user)):
    db.scalar(select(Thread).where(Thread.id == tid, Thread.user_id == user)) \
        or (_ for _ in ()).throw(HTTPException(404))
    q = db.scalars(select(Message).where(Message.thread_id == tid).order_by(Message.ts)).all()
    def to_dict(m):
        img = m.images[0].data if m.images else None
        return {"role": m.role, "content": m.content, "image": img}
    return [to_dict(m) for m in q]

# 4) ì±„íŒ… (ì™„ë£Œ ì‘ë‹µ) ----------------------------------------------------------
class ChatReq(BaseModel):
    thread_id: str
    question: str
    image: Optional[str] = None

@app.post("/chat")
def chat(req: ChatReq, db: Session = Depends(get_db), user=Depends(current_user)):
    db.scalar(select(Thread).where(Thread.id == req.thread_id, Thread.user_id == user)) \
        or (_ for _ in ()).throw(HTTPException(404))

    human = HumanMessage(content=req.question)
    if req.image:
        human = HumanMessage(content=[
            {"type": "text", "text": req.question},
            {"type": "image_url", "image_url": {"url": req.image, "detail": "auto"}},
        ])
    state = {"messages": [human]}
    cfg   = RunnableConfig(configurable={"thread_id": req.thread_id})
    answer = agent.invoke(state, cfg)["messages"][-1].content

    user_msg = Message(thread_id=req.thread_id, role="user", content=req.question)
    if req.image:
        user_msg.images.append(MessageImage(data=req.image))
    db.add_all([
        user_msg,
        Message(thread_id=req.thread_id, role="assistant", content=answer),
    ]); db.commit()
    return {"role": "assistant", "content": answer}

# 5) ì±„íŒ… (ê¸€ì ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°) -------------------------------------------------
@app.post("/chat/stream")
async def chat_stream(req: ChatReq, db: Session = Depends(get_db), user=Depends(current_user)):
    # â”€â”€ ê¶Œí•œ í™•ì¸ --------------------------------------------------------
    db.scalar(select(Thread).where(Thread.id == req.thread_id, Thread.user_id == user)) \
        or (_ for _ in ()).throw(HTTPException(404))

    # â”€â”€ ì…ë ¥ ë©”ì‹œì§€ ------------------------------------------------------
    if req.image:
        human = HumanMessage(content=[
            {"type": "text", "text": req.question},
            {"type": "image_url", "image_url": {"url": req.image, "detail": "auto"}},
        ])
    else:
        human = HumanMessage(content=req.question)

    state = {"messages": [human]}
    cfg   = RunnableConfig(configurable={"thread_id": req.thread_id})

    # â”€â”€ LangGraph ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë° --------------------------------------
    # â”€â”€â”€ /chat/stream â†’ gen() íŒŒì„œ ë³´ê°• â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def gen():
        assistant = ""
        async for ev in agent.astream_events(state, cfg, version="v1"):
            if not isinstance(ev, dict):
                continue                      # ë¬¸ìì—´ ì´ë²¤íŠ¸ ë¬´ì‹œ
            t = ev.get("type") or ev.get("event")
            if t is None:
                continue
            if t == "on_tool_start":
                yield f"[STEP] ğŸ”§ {ev['name']} í˜¸ì¶œ\n".encode()
            elif t == "on_tool_end":
                yield f"[OBS] {ev['output']}\n".encode()
            elif t == "on_llm_end":
                chunk = ev["output"]["choices"][0]["message"]["content"]
                assistant += chunk
                yield chunk.encode()

        # â”€â”€ DB ê¸°ë¡ ----------------------------------------------------
        user_msg = Message(thread_id=req.thread_id, role="user", content=req.question)
        if req.image:
            user_msg.images.append(MessageImage(data=req.image))
        db.add_all([
            user_msg,
            Message(thread_id=req.thread_id, role="assistant", content=assistant),
        ])
        db.commit()
        yield b"[DONE]"

    return StreamingResponse(
        gen(),
        media_type="text/plain; charset=utf-8",
        headers={
            "X-Accel-Buffering": "no",
            "Cache-Control": "no-cache",
        },
    )


